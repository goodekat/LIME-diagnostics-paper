\documentclass[9pt]{article}

\usepackage[margin=1in]{geometry}

\title{Supplemental Material Corresponding to ``Visual Diagnostics of an Explainer Model -- Tools for the Assessment of LIME Explanations"}
\date{}

\begin{document}

\maketitle

<<setup, echo = FALSE, include = FALSE>>=
# Specify global options
knitr::opts_chunk$set(
  warning = FALSE,
  message = FALSE,
  echo = FALSE,
  fig.keep = 'high',
  fig.align = 'center',
  dev = c("cairo_pdf", "cairo_ps"),
  dev.args = list(fallback_resolution = 800),
  dpi = 1200
)

# Load packages
library(Cairo)
library(cowplot)
library(dplyr)
library(forcats)
library(ggplot2)
library(gretchenalbrecht) #remotes::install_github("dicook/gretchenalbrecht")
library(lime) #remotes::install_github("goodekat/lime")
library(limeaid) #remotes::install_github("goodekat/limeaid")
library(tidyr)

# Specify the (base) font size (fs) and font (ff) for all plots
fs = 7
ff = "Helvetica"
@

\section{Extreme Feature Heatmap Scenarios} \label{feat-heat-ex}

Two hypothetical examples of feature heatmaps are included in Figure \ref{fig:figure-s1}. The plots are created with the assumption that LIME is applied to select the top feature out of $p=4$  features for $n=10$ cases with $t=5$ sets of tuning parameter values. Situation 1 (left) is an example where the features selected are consistent across tuning parameter values within a case but vary across cases within a tuning parameter value. This is the ideal situation, because the LIME explanations do not depend on the tuning parameters but do depend on the location of the observation in the feature space. Situation 2 (right) is an example where the selected features vary across tuning parameter values within a case but are consistent across cases within a tuning parameter value. This situation indicates that the features selected by LIME are dependent on the tuning parameters, and the explanations may not be  local, because the same feature is chosen regardless of the case. In practice, it is expected that the plot will exhibit a combination of these two situations.

\vspace{0.5cm}

\renewcommand{\thefigure}{S1}
\begin{figure}[!h]
<<figure-s1, out.width = '4.5in', fig.width = 8, fig.height = 3.5>>=

# Specify the figure size (for determining font size)
fs1_ow = 4.5
fs1_fw = 8
fs1_fs = fs * (fs1_fw / fs1_ow)

# Specify the number of cases and LIME input options
ncases = 10
ninputs = 5

# Create a good case of chosen feature example data
set.seed(20191008)
heatmap_data_good <-
  tibble(
    case = factor(rep(1:ncases, each = ninputs),
                  levels = ncases:1),
    input = factor(rep(1:ninputs, ncases)),
    feature = factor(c(
      rep(1, 5),
      rep(2, 5),
      rep(3, 5),
      rep(1, 5),
      rep(1, 5),
      rep(4, 5),
      rep(1, 5),
      rep(3, 5),
      rep(1, 5),
      rep(4, 5)
    ))
  ) %>%
  mutate(input = fct_recode(
    input,
    "A" = "1",
    "B" = "2",
    "C" = "3",
    "D" = "4",
    "E" = "5"
  ))

# Create the conceptual good heatmap
heatmap_plot_good <- ggplot(data = heatmap_data_good,
                            mapping = aes(
                              x = input,
                              y = case,
                              fill = feature,
                              color = feature
                            )) +
  geom_tile() +
  labs(
    x = "Tuning Parameter Value",
    y = "Case",
    fill = "Feature",
    color = "Feature",
    title = "Situation 1",
    subtitle = "Consistent Explanations"
  ) +
  theme_bw(base_family = ff, base_size = fs1_fs) +
  scale_fill_grey() +
  scale_color_grey() +
  theme(legend.position = "none", 
        plot.title = element_text(size = fs1_fs))

# Create a bad case of chosen feature example data
set.seed(20190627)
heatmap_data_bad <- tibble(
  case = factor(rep(1:ncases, ninputs),
                levels = ncases:1),
  input = factor(rep(1:ninputs, each = ncases)),
  feature = factor(rep(c(1, 2, 4, 3, 2), each = 10))
) %>%
  mutate(input = fct_recode(
    input,
    "A" = "1",
    "B" = "2",
    "C" = "3",
    "D" = "4",
    "E" = "5"
  ))

# Create the conceptual bad heat map
heatmap_plot_bad <- ggplot(data = heatmap_data_bad,
                           mapping = aes(
                             x = input,
                             y = case,
                             fill = feature,
                             color = feature
                           )) +
  geom_tile() +
  labs(
    x = "Tuning Parameter Value",
    y = "Case",
    fill = "Feature",
    color = "Feature",
    title = "Situation 2",
    subtitle = "Inconsistent Explanations"
  ) +
  theme_bw(base_family = ff, base_size = fs1_fs) +
  theme(plot.title = element_text(size = fs1_fs)) +
  scale_fill_grey() +
  scale_color_grey()

heatmap_leg <- get_legend(heatmap_plot_bad)
heatmap_plot_bad <-
  heatmap_plot_bad + theme(legend.position = 'none')

# Join the plots
plot_grid(
  heatmap_plot_good,
  heatmap_plot_bad,
  heatmap_leg,
  nrow = 1,
  rel_widths = c(0.43, 0.43, 0.14)
)

@
\caption{Hypothetical examples of feature heatmaps in two possible situations. (Left) Situation 1 is the ideal, because the explanations vary across cases but do not depend on tuning parameter values. (Right) Situation 2 suggests global explanations and extreme explanation dependence on tuning parameter values.}
\label{fig:figure-s1}
\end{figure}

\section{Additional Bullet Matching Explanation Scatterplots} \label{bullets-plus}

Figures \ref{fig:figure-s2} and \ref{fig:figure-s3} include visual representations of LIME explanations from the \emph{lime} R package (left) and explanation scatterplots (right) for a known match observation in the the bullet example referred to as case M. The explanations in Figures \ref{fig:figure-s2} and \ref{fig:figure-s3} are obtained using 4-quantile-bins and Figure 4-equal-bins, respectively. The explanations appear to be faithful to the random forest than those associated with case NM in Section 4 of ``Visual Diagnostics of an Explainer Model -- Tools for the Assessment of LIME Explanations". However, the intersections of the bins are still not well aligned with the regions containing similar probabilities produced by the random forest. Figure \ref{fig:figure-s4} includes explanation scatterplots using the kernel density simulation method for both cases M and NM from the bullet example.

\vspace{0.5cm}

<<>>=
# Load the cleaned explanations
bullet_explain_perms_clean <- readRDS("../data/bullet-explain-perms-clean.rds")
@

\renewcommand{\thefigure}{S2}
\begin{figure*}[!h]
<<figure-s2, out.width = '6.5in', fig.width = 14, fig.height = 7>>=

# Specify the figure size (for determining font size)
fs2_ow = 6.5
fs2_fw = 14
fs2_fs = fs * (fs2_fw / fs2_ow)
fs2_ls = 0.5 * (fs2_fw / fs2_ow)

# Create a theme for the lime explanation visualizations
bullet_explain_plot_theme <-
  list(
    scale_fill_manual(values = c("darkorange", "grey50")),
    theme(
      text = element_text(family = ff, size = fs2_fs),
      strip.text.x = element_text(face = "plain", size = fs2_fs),
      aspect.ratio = 1
    )
  )

# Create theme for explanation scatterplots
bullet_eoi_plot_theme <-
  list(
    scale_color_gradient2(
      low = "grey50",
      high = "darkorange",
      midpoint = 0.5,
      limits = c(0, 1)
    ),
    scale_fill_gradient2(
      low = "grey50",
      high = "darkorange",
      midpoint = 0.5,
      limits = c(0, 1)
    ),
    theme_bw(base_family = ff, base_size = fs2_fs),
    theme(
      aspect.ratio = 1,
      plot.title = element_text(size = fs2_fs),
      strip.text.x = element_text(size = fs2_fs),
      strip.text.y = element_text(size = fs2_fs),
      strip.placement = "outside",
      strip.background = element_rect(color = "white", fill = "white")
    ),
    guides(size = guide_legend(nrow = 2, byrow = T), 
           linetype = guide_legend(override.aes = list(color = c("grey50", "darkorange"))))
  )

# Create the lime explanation visualizations
pfM_3qb <- plot_features(bullet_explain_perms_clean[1:3,]) + bullet_explain_plot_theme

# Create the explanation scatterplots
eoiM_3qb <-
  plot_explain_scatter(
    bullet_explain_perms_clean[1:3, ],
    alpha = 0.9,
    weights = TRUE,
    line_size = fs2_ls
  ) +
  bullet_eoi_plot_theme +
  guides(linetype = guide_legend(override.aes = list(color = c("darkorange"))))

# Join the plots
plot_grid(
  pfM_3qb,
  eoiM_3qb,
  nrow = 1,
  rel_widths = c(0.35, 0.65)
)

@
\caption{Explanation plot from \emph{lime} R package (left) and explanation scatterplot (right) for case M in the bullet test data for 4-quantile-bins.}
\label{fig:figure-s2}
\end{figure*}

\renewcommand{\thefigure}{S3}
\begin{figure*}[!h]
<<figure-s3, out.width = '6.5in', fig.width = 14, fig.height = 7>>=

# Specify the figure size (for determining font size)
fs3_ow = 6.5
fs3_fw = 14
fs3_fs = fs * (fs3_fw / fs3_ow)
fs3_ls = 0.5 * (fs3_fw / fs3_ow)

# Create the lime explanation visualizations
pfM_3eb <- plot_features(bullet_explain_perms_clean[7:9,]) + bullet_explain_plot_theme

# Create the explanation scatterplots
eoiM_3eb <-
  plot_explain_scatter(
    bullet_explain_perms_clean[7:9, ],
    alpha = 0.9,
    weights = TRUE,
    line_size = fs3_ls
  ) +
  bullet_eoi_plot_theme + 
  guides(linetype = guide_legend(override.aes = list(color = c("darkorange"))))

# Join the plots
plot_grid(
  pfM_3eb,
  eoiM_3eb,
  nrow = 1,
  rel_widths = c(0.35, 0.65)
)

@
\caption{Explanation plot from \emph{lime} R package (left) and explanation scatterplot (right) for case M in the bullet test data for 4-equal-bins.}
\label{fig:figure-s3}
\end{figure*}

\renewcommand{\thefigure}{S4}
\begin{figure*}[!h]
<<figure-s4, out.width = '6.5in', fig.width = 12, fig.height = 10>>=

# Specify the figure size (for determining font size and line size)
fs4_ow = 6.5
fs4_fw = 12
fs4_fs = fs * (fs4_fw / fs4_ow)
fs4_ls = 0.5 * (fs4_fw / fs4_ow)

# Create the explanation scatterplot: case M, kernel density
bullet_es_M <-
  plot_explain_scatter(
    bullet_explain_perms_clean %>% filter(case == "M", sim_method == "kernel_density"),
    alpha = 0.75,
    title.opt = TRUE,
    line_size = fs4_ls
  ) +
  scale_fill_gradient2(
    low = "grey50",
    high = "darkorange",
    midpoint = 0.5,
    limits = c(0, 1)
  ) +
  theme_bw(base_family = ff, base_size = fs4_fs) +
  theme(
    aspect.ratio = 1,
    strip.background = element_rect(fill = "white", color = "white"),
    strip.placement = "outside",
    strip.text.x = element_text(size = fs4_fs),
    plot.title = element_text(size = fs4_fs)
  )

# Create the explanation scatterplot: case NM, kernel density
bullet_es_NM <-
  plot_explain_scatter(
    bullet_explain_perms_clean %>% filter(case == "NM", sim_method == "kernel_density"),
    alpha = 0.75,
    title.opt = TRUE, 
    line_size = fs4_ls
  ) +
  scale_fill_gradient2(
    low = "grey50",
    high = "darkorange",
    midpoint = 0.5,
    limits = c(0, 1)
  ) +
  theme_bw(base_family = ff, base_size = fs4_fs) +
  theme(
    aspect.ratio = 1,
    strip.background = element_rect(fill = "white", color = "white"),
    strip.placement = "outside",
    strip.text.x = element_text(size = fs4_fs), 
    plot.title = element_text(size = fs4_fs)
  )

# Join the plots
plot_grid(bullet_es_M, bullet_es_NM, nrow = 2)

@
\caption{Explanation scatterplots for LIME explanations using kernel density simulation for the cases M (top) and NM (bottom) of the bullet comparison test data.}
\label{fig:figure-s4}
\end{figure*}

\end{document}
