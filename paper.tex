\documentclass[AMS,STIX2COL]{WileyNJD-v2}

% Packages
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{natbib}
\usepackage{xcolor}

% Commands
\definecolor{orange}{rgb}{0.94, 0.59, 0.19}
\definecolor{purple}{rgb}{0.5, 0.0, 0.5}
\definecolor{teal}{rgb}{0, 0.502, 0.502}
\newcommand{\hh}[1]{\textcolor{orange}{#1}}
\newcommand{\kgc}[1]{\textcolor{purple}{#1}}
\newcommand{\kge}[1]{\textcolor{teal}{#1}}
\newcommand{\data}{sine data}
\renewcommand{\sout}[1]{\unskip}

% Set up for ASA data science journal
\articletype{Research Article}
\received{XX XX XXXX}
\revised{XX XX XXXX}
\accepted{XX XX XXXX}
\raggedbottom

\usepackage{Sweave}
\begin{document}
\input{paper-concordance}

% Paper header (title and authors)
\title{Visual Diagnostics of an  Explainer Model -- Tools for the Assessment of LIME Explanations}
\author[1]{Katherine Goode*}
\author[1,2]{Heike Hofmann}
\authormark{Goode and Hofmann}
\address[1]{\orgdiv{Department of Statistics}, \orgname{Iowa State University}, \orgaddress{\state{Iowa}, \country{United States}}}
\address[2]{\orgdiv{Center for Statistics and Applications in Forensic Evidence (CSAFE)}, \orgname{Iowa State University}, \orgaddress{\state{Iowa}, \country{United States}}}
\corres{*Katherine Goode, Department of Statistics, Iowa State University, Ames, IA. \email{kgoode@iastate.edu}}

% Abstract and keywords
\abstract[Abstract]{The importance of providing explanations for predictions made by black-box models has led to the development of explainer model  methods such as LIME (local interpretable model-agnostic explanations). LIME uses a surrogate model to explain the relationship between predictor variables and predictions from a black-box model in a local region around a prediction of interest. However, the quality of the resulting explanations relies on how well the explainer model captures the black-box model in a specified local region. Here we introduce three visual diagnostics to assess the quality of LIME explanations: (1) explanation scatterplots, (2) assessment metric plots, and (3) feature heatmaps. We apply the visual diagnostics to a forensics bullet matching dataset to show examples where LIME explanations depend on the tuning parameter values and the explainer model oversimplifies the black-box model. Our examples raise concerns about claims made of LIME that are similar to other criticisms in the literature.}
\keywords{explainable machine learning, black-box models, interpretability, statistical graphics, data science}

% Citation information
\jnlcitation{
\cname{\author{Goode K.}, \author{H. Hofmann}, }
\cyear{2020},
\ctitle{Visual Diagnostics of an  Explainer Model -- Tools for the Assessment of LIME Explanations},
\cjournal{Stat Anal Data Min: The ASA Data Sci Journal},
\cvol{volume, number and page}.}

\maketitle


\section{Introduction}

\begin{Schunk}
\begin{Sinput}
> 
> # # Simulate example data
> # set.seed(20190624)
> # lime_data <-
> #   data.frame(
> #     feature1 = sort(runif(250, 0, 1)),
> #     feature2 = sample(x = 1:250, size = 250, replace = FALSE)) %>%
> #   mutate(
> #     feature1_stnd = (feature1 - mean(feature1)) / sd(feature1),
> #     feature2_stnd = (feature2 - mean(feature2)) / sd(feature2),
> #     prediction = if_else(feature1 >= 0 & feature1 < 0.1,
> #                          (0.3 * feature1) + rnorm(n(), 0, 0.01),
> #                  if_else(feature1 >= 0.1 & feature1 < 0.3,
> #                          rbeta(n(), 1, 0.5),
> #                  if_else(feature1 >= 0.3 & feature1 < 0.5,
> #                          sin(pi* feature1) + rnorm(n(), 0, 0.5),
> #                  if_else(feature1 >= 0.5 & feature1 < 0.8,
> #                          -(sin(pi* feature1) + rnorm(n(), 0, 0.1)) + 1,
> #                  if_else(feature1 >= 0.8 & feature1 < 0.9,
> #                          0.5 + runif(n(), -0.5, 0.5),
> #                          0.5 + rnorm(n(), 0, 0.3))))))) %>%
> #   bind_rows(
> #     data.frame(feature1 = rep(1, 30) + rnorm(5, 0, 0.05),
> #            feature2 = rep(245, 30) + rnorm(5, 0, 1),
> #            prediction = rep(0, 30) + rnorm(5, 0, 0.05)) %>%
> #   mutate(feature1_stnd = (feature1 - mean(feature1)) / sd(feature1),
> #          feature2_stnd = (feature2 - mean(feature2)) / sd(feature2)))
> # 
> # # Specify a prediction of interest
> # prediction_of_interest <-
> #   data.frame(feature1 = 0.07, feature2 = 200) %>%
> #   mutate(feature1_stnd = (feature1 - mean(lime_data$feature1)) /
> #            sd(lime_data$feature1),
> #          feature2_stnd = (feature2 - mean(lime_data$feature2)) /
> #            sd(lime_data$feature2),
> #          prediction = 0.05,
> #          color = factor("Prediction \nof Interest"))
> # 
> # # Specify the gower exponents
> # good_gower_power <- 50
> # bad_gower_power <- 1
> # 
> # # Compute the good distances between the prediction of interest
> # # and all other observations
> # lime_data$distance_good <-
> #   (1 - gower_dist(x = prediction_of_interest %>%
> #                     select(feature1_stnd, feature2_stnd),
> #                   y = lime_data %>%
> #                     select(feature1_stnd,
> #                            feature2_stnd)))^good_gower_power
> # 
> # # Compute the bad distances between the prediction of interest
> # # and all other observations
> # lime_data$distance_bad <-
> #   (1 - gower_dist(x = prediction_of_interest %>%
> #                     select(feature1_stnd, feature2_stnd),
> #                   y = lime_data %>%
> #                     select(feature1_stnd,
> #                            feature2_stnd)))^bad_gower_power
> # 
> # # Prepare the data for plotting
> # lime_data_gathered <- lime_data %>%
> #   gather(feature, feature_stnd_value,
> #          feature1_stnd:feature2_stnd) %>%
> #   gather(distance, distance_value, distance_good:distance_bad) %>%
> #   mutate(distance = fct_recode(distance,
> #                                "good" = "distance_good",
> #                                "bad" = "distance_bad"),
> #          feature = fct_recode(feature,
> #                               "Feature 1" = "feature1_stnd",
> #                               "Feature 2" = "feature2_stnd"))
> # 
> # # Prepare the prediction of interest data for plotting
> # prediction_of_interest_gathered <- prediction_of_interest %>%
> #   select(-feature1, -feature2) %>%
> #   gather(feature, feature_value, feature1_stnd, feature2_stnd) %>%
> #   mutate(feature = fct_recode(feature,
> #                               "Feature 1" = "feature1_stnd",
> #                               "Feature 2" = "feature2_stnd"))
> 
\end{Sinput}
\end{Schunk}

\begin{Schunk}
\begin{Sinput}
> 
> # # Fit the good interpretable explainer model
> # explainer_good <-
> #   glmnet(x = lime_data %>% select(feature1_stnd, feature2_stnd)
> #          %>% as.matrix(),
> #          y = lime_data$prediction,
> #          alpha = 0,
> #          lambda = 1,
> #          weights = lime_data$distance_good)
> # 
> # # Fit the bad interpretable explainer model
> # explainer_bad <-
> #   glmnet(x = lime_data %>% select(feature1_stnd, feature2_stnd)
> #          %>% as.matrix(),
> #          y = lime_data$prediction,
> #          alpha = 0,
> #          lambda = 1,
> #          weights = lime_data$distance_bad)
> # 
> # # Join the coefficients from the explainer model into a dataframe
> # coefs_data <- data.frame(case = c("good", "bad"),
> #                          b0 = c(coef(explainer_good)[1],
> #                                 coef(explainer_bad)[1]),
> #                          b1 = c(coef(explainer_good)[2],
> #                                 coef(explainer_bad)[2]),
> #                          b2 = c(coef(explainer_good)[3],
> #                                 coef(explainer_bad)[3])) %>%
> #   mutate(feature1 = b0 + b2*prediction_of_interest$feature2_stnd,
> #          feature2 = b0 + b1*prediction_of_interest$feature1_stnd) %>%
> #   gather(key = feature, value = int, feature1:feature2) %>%
> #   mutate(slope = c(coef(explainer_good)[2],
> #                    coef(explainer_good)[3],
> #                    coef(explainer_bad)[2],
> #                    coef(explainer_bad)[3]),
> #          feature = fct_recode(feature,
> #                               "Feature 1" = "feature1",
> #                               "Feature 2" = "feature2"))
> 
\end{Sinput}
\end{Schunk}

\begin{Schunk}
\begin{Sinput}
> # Specify the gower exponents
> good_gower_power <- 0.00000000000000005
> bad_gower_power <- 1
> # Specify a prediction of interest
> poi <-
+   data.frame(
+     poi = "Prediction \nof Interest",
+     feature = 0.1,
+     prediction = 0.05
+   )
> # Simulate example data
> set.seed(20190624)
> concept_data <-
+   data.frame(poi = "Training Data", 
+              feature = sort(c(runif(100, 0, 1), runif(250, 0, 7)))) %>%
+   mutate(prediction = sin(feature) + rnorm(350, 0, 0.25)) %>%
+   bind_rows(poi)
> # Compute the good distances between the prediction of interest
> # and all other observations
> concept_data$weights_good <-
+   1 - (gower_dist(
+     x = poi %>% select(feature),
+     y = concept_data %>% select(feature)
+   )) ^ good_gower_power
> # Compute the bad distances between the prediction of interest
> # and all other observations
> concept_data$weights_bad <-
+   1 - (gower_dist(
+     x = poi %>% select(feature),
+     y = concept_data %>% select(feature)
+   )) ^ bad_gower_power
> # Fit the good and bad interpretable explainer models
> explainer_good <-
+   lm(prediction ~ feature, data = concept_data, weights = weights_good)
> explainer_bad <-
+   lm(prediction ~ feature, data = concept_data, weights = weights_bad)
> # Create labels for the gower powers
> good_power_label <-
+   paste0("Faithful Local Explainer \n(exponent used to compute weights: ",
+          good_gower_power,
+          ")")
> bad_power_label <-
+   paste0("Unfaithful Local Explainer \n(exponent used to compute weights: ",
+          bad_gower_power,
+          ")")
> # Join the coefficients from the explainer model into a dataframe
> coefs_data <-
+   data.frame(
+     case = c(good_power_label, bad_power_label),
+     b0 = c(coef(explainer_good)[1],
+            coef(explainer_bad)[1]),
+     b1 = c(coef(explainer_good)[2],
+            coef(explainer_bad)[2]),
+     feature = 6,
+     prediction = 1.6
+   ) %>%
+   mutate(text = paste0("Slope: ", round(b1, 3)))
> # Prepare data for plotting
> concept_data_long <-
+   concept_data %>%
+   pivot_longer(names_to = "case",
+                values_to = "weight",
+                cols = weights_good:weights_bad) %>%
+   mutate(case = ifelse(case == "weights_good", good_power_label, bad_power_label))
\end{Sinput}
\end{Schunk}

\begin{figure*}[!thp]
\begin{Schunk}
\begin{Sinput}
> # Specify the figure size (for determining font size)
> f1_ow = 6.5
> f1_fw = 7.95
> f1_fs = fs * (f1_fw / f1_ow)
> # Plot of good explainer model
> ggplot() +
+   facet_grid(. ~ case) +
+   geom_point(
+     data = concept_data_long,
+     mapping = aes(
+       x = feature,
+       y = prediction,
+       fill = poi,
+       color = poi,
+       shape = poi,
+       alpha = poi,
+       size = weight
+     )
+   ) +
+   geom_abline(
+     data = coefs_data,
+     mapping = aes(intercept = b0, slope = b1),
+     size = 1
+   ) +
+   scale_fill_manual(values = c("#FAAA72", "grey30")) +
+   scale_color_manual(values = c("grey30", "grey30")) +
+   scale_alpha_manual(values = c(0.75, 0.6)) +
+   scale_shape_manual(values = c(23, 21)) +
+   geom_text(
+     data = coefs_data,
+     mapping = aes(x = feature,
+                   y = prediction,
+                   label = text),
+     family = ff,
+     size = f1_fs / 2.85
+   ) +
+   labs(x = "Black-Box Model Feature",
+        y = "Black-Box Prediction",
+        size = "Weight", 
+        fill = "", 
+        color = "",
+        alpha = "",
+        shape = "") +
+   theme_linedraw(base_family = ff, base_size = f1_fs) +
+   theme(
+     panel.grid.major = element_blank(),
+     panel.grid.minor = element_blank(),
+     axis.text.x = element_blank(),
+     axis.ticks.x = element_blank(),
+     axis.text.y = element_blank(),
+     axis.ticks.y = element_blank(),
+     strip.placement = "outside",
+     strip.background = element_rect(color = "white", fill = "white"),
+     strip.text.x = element_text(size = f1_fs, color = "black"),
+     plot.title = element_text(size = f1_fs)
+   ) +
+   guides(
+     fill = guide_legend(order = 1, override.aes = list(size = 5)),
+     color = guide_legend(order = 1),
+     shape = guide_legend(order = 1),
+     alpha = guide_legend(order = 1),
+     size = guide_legend(
+       order = 2,
+       override.aes = list(color = "grey30", alpha = 0.6)
+     )
+   )
> 
> # # Plot of good explainer model
> # ggplot() +
> #   facet_grid(. ~ feature, switch = "x") +
> #   geom_point(
> #     data = lime_data_gathered %>% mutate(
> #       feature = fct_recode(
> #         feature,
> #         "Feature 1 (standardized)" = "Feature 1",
> #         "Feature 2 (standardized)" = "Feature 2"
> #       )
> #     ),
> #     mapping = aes(
> #       x = feature_stnd_value,
> #       y = prediction,
> #       size = distance_value,
> #       color = distance
> #     ),
> #     alpha = 0.6
> #   ) +
> #   geom_abline(
> #     data = coefs_data %>%
> #       filter(case == "good") %>%
> #       mutate(
> #         feature = fct_recode(
> #           feature,
> #           "Feature 1 (standardized)" = "Feature 1",
> #           "Feature 2 (standardized)" = "Feature 2"
> #           )
> #         ),
> #     mapping = aes(intercept = int, slope = slope),
> #     size = 1
> #   ) +
> #   scale_color_manual(values = c(NA, "grey30"), guide = "none") +
> #   geom_point(
> #     data = prediction_of_interest_gathered %>% mutate(
> #       feature = fct_recode(
> #         feature,
> #         "Feature 1 (standardized)" = "Feature 1",
> #         "Feature 2 (standardized)" = "Feature 2"
> #       )
> #     ),
> #     mapping = aes(x = feature_value,
> #                   y = prediction,
> #                   fill = color),
> #     color = "black",
> #     size = 5,
> #     shape = 23,
> #     alpha = 0.75
> #   ) +
> #   scale_fill_manual(values = "#FAAA72") +
> #   geom_text(
> #     data = data.frame(
> #       feature_stnd_value = 1.2,
> #       prediction = 1.6,
> #       feature = c("Feature 1 (standardized)", "Feature 2 (standardized)"),
> #       slope = c(
> #         paste(
> #           "Slope:",
> #           coefs_data %>%
> #             filter(case == "good",
> #                    feature == "Feature 1") %>%
> #             pull(slope) %>%
> #             round(3)
> #         ),
> #         paste(
> #           "Slope:",
> #           coefs_data %>%
> #             filter(case == "good",
> #                    feature == "Feature 2") %>%
> #             pull(slope) %>%
> #             round(3)
> #         )
> #       )
> #     ),
> #     mapping = aes(x = feature_stnd_value,
> #                   y = prediction,
> #                   label = slope),
> #     family = ff,
> #     size = f1_fs / 2.85
> #   ) +
> #   labs(
> #     x = "",
> #     y = "Black-Box Prediction",
> #     title = "Conceptual Depiction of a Faithful Local Explainer Model",
> #     subtitle = paste("Gower Distance Metric Exponent:", good_gower_power),
> #     fill = "",
> #     alpha = "Weight",
> #     size = "Weight"
> #   ) +
> #   theme_linedraw(base_family = ff, base_size = f1_fs) +
> #   theme(
> #     panel.grid.major = element_blank(),
> #     panel.grid.minor = element_blank(),
> #     axis.text.x = element_blank(),
> #     axis.ticks.x = element_blank(),
> #     axis.text.y = element_blank(),
> #     axis.ticks.y = element_blank(),
> #     strip.placement = "outside",
> #     strip.background = element_rect(color = "white", fill = "white"),
> #     strip.text.x = element_text(size = f1_fs, color = "black"),
> #     plot.title = element_text(size = f1_fs)
> #   ) +
> #   guides(
> #     fill = guide_legend(order = 1),
> #     size = guide_legend(order = 2),
> #     alpha = guide_legend(order = 2)
> #   )
> 
\end{Sinput}
\end{Schunk}
